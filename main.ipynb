{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.linear_model import LogisticRegression, Lasso\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from deap import creator, base, tools, algorithms\n",
    "from sklearn.metrics import f1_score\n",
    "import sys\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg(l):\n",
    "    \"\"\"\n",
    "    Returns the average between list elements\n",
    "    \"\"\"\n",
    "    return (sum(l)/float(len(l)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFitness(individual, X, y): ## ds\n",
    "    \"\"\"\n",
    "    Feature subset fitness function\n",
    "    \"\"\"\n",
    "\n",
    "    if(individual.count(0) != len(individual)):\n",
    "        # get index with value 0\n",
    "        cols = [index for index in range(\n",
    "            len(individual)) if individual[index] == 0]\n",
    "\n",
    "        # get features subset\n",
    "        X_parsed = X.drop(X.columns[cols], axis=1)\n",
    "        X_subset = pd.get_dummies(X_parsed)\n",
    "\n",
    "        # apply classification algorithm\n",
    "        clf = LogisticRegression()\n",
    "\n",
    "        return (avg(cross_val_score(clf, X_subset, y, cv=5)),)\n",
    "    else:\n",
    "        return(0,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def geneticAlgorithm(X, y, n_population, n_generation):\n",
    "    \"\"\"\n",
    "    Deap global variables\n",
    "    Initialize variables to use eaSimple\n",
    "    \"\"\"\n",
    "    # create individual\n",
    "    creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
    "    creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n",
    "\n",
    "    # create toolbox\n",
    "    toolbox = base.Toolbox()\n",
    "    toolbox.register(\"attr_bool\", random.randint, 0, 1)\n",
    "    toolbox.register(\"individual\", tools.initRepeat,\n",
    "                     creator.Individual, toolbox.attr_bool, len(X.columns))\n",
    "    toolbox.register(\"population\", tools.initRepeat, list,\n",
    "                     toolbox.individual)\n",
    "    toolbox.register(\"evaluate\", getFitness, X=X, y=y)\n",
    "    toolbox.register(\"mate\", tools.cxOnePoint)\n",
    "    toolbox.register(\"mutate\", tools.mutFlipBit, indpb=0.05)\n",
    "    toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
    "\n",
    "    # initialize parameters\n",
    "    pop = toolbox.population(n=n_population)\n",
    "\n",
    "    hof = tools.HallOfFame(n_population * n_generation)\n",
    "    stats = tools.Statistics(lambda ind: ind.fitness.values)\n",
    "    stats.register(\"avg\", np.mean)\n",
    "    stats.register(\"min\", np.min)\n",
    "    stats.register(\"max\", np.max)\n",
    "    \n",
    "    print(\"xx\")\n",
    "    # genetic algorithm\n",
    "    pop, log = algorithms.eaSimple(pop, toolbox, cxpb=0.5, mutpb=0.2,\n",
    "                                   ngen=n_generation, stats=stats, halloffame=hof,\n",
    "                                   verbose=True)\n",
    "    print(\" hall of frame :\", hof.maxsize)\n",
    "\n",
    "    # return hall of fame\n",
    "    return hof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bestIndividual(hof, X, y):\n",
    "    \"\"\"\n",
    "    Get the best individual\n",
    "    \"\"\"\n",
    "    maxAccurcy = 0.0\n",
    "    for individual in hof:\n",
    "        print(type(individual.fitness.values[0]))\n",
    "        if(individual.fitness.values[0] > maxAccurcy):\n",
    "            maxAccurcy = individual.fitness.values[0]\n",
    "            _individual = individual\n",
    "\n",
    "    _individualHeader = [list(X)[i] for i in range(\n",
    "        len(_individual)) if _individual[i] == 1]\n",
    "    return _individual.fitness.values, _individual, _individualHeader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getArguments():\n",
    "    \"\"\"\n",
    "    Get argumments from command-line\n",
    "    If pass only dataframe path, pop and gen will be default\n",
    "    \"\"\"\n",
    "    dfPath = sys.argv[1]\n",
    "    if(len(sys.argv) == 4):\n",
    "        pop = int(sys.argv[2])\n",
    "        gen = int(sys.argv[3])\n",
    "    else:\n",
    "        pop = 10\n",
    "        gen = 2\n",
    "    return dfPath, pop, gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # get dataframe path, population number and generation number from command-line argument\n",
    "# n_pop = 20\n",
    "# n_gen = 6\n",
    "# # read dataframe from csv\n",
    "# df = pd.read_csv('datasets/nuclear.csv', sep=',')\n",
    "\n",
    "# # encode labels column to numbers\n",
    "# le = LabelEncoder()\n",
    "# le.fit(df.iloc[:, -1])\n",
    "# y = le.transform(df.iloc[:, -1]) # label\n",
    "# y_test = y[:20]\n",
    "# X = df.iloc[:, :-1] # data\n",
    "\n",
    "# # get accuracy with all features\n",
    "# individual = [1 for i in range(len(X.columns))] # true column (feature)\n",
    "# print(\"Accuracy with all features: \\t\" +\n",
    "#       str(getFitness(individual, X, y)) + \"\\n\")\n",
    "\n",
    "# # apply genetic algorithm\n",
    "# hof = geneticAlgorithm(X, y, n_pop, n_gen)\n",
    "\n",
    "# # select the best individual\n",
    "# accuracy, individual, header = bestIndividual(hof, X, y)\n",
    "# print('Best Accuracy: \\t' + str(accuracy))\n",
    "# print('Number of Features in Subset: \\t' + str(individual.count(1)))\n",
    "# print('Individual: \\t\\t' + str(individual))\n",
    "# print('Feature Subset\\t: ' + str(header))\n",
    "\n",
    "# print('\\n\\ncreating a new classifier with the result')\n",
    "\n",
    "# # read dataframe from csv one more time\n",
    "# df = pd.read_csv('datasets/nuclear.csv', sep=',')\n",
    "\n",
    "# # with feature subset\n",
    "# X = df[header]\n",
    "\n",
    "# clf = LogisticRegression()\n",
    "\n",
    "# scores = cross_val_score(clf, X, y, cv=5)\n",
    "# print(\"Accuracy with Feature Subset: \\t\" + str(avg(scores)) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wine():\n",
    "    df_red = pd.read_csv('../cso_cnn/datasets/winequality_red.csv')\n",
    "    df_white = pd.read_csv('../cso_cnn/datasets/winequality_white.csv')\n",
    "    df_red['color'] = \"R\"\n",
    "    df_white['color'] = \"W\"\n",
    "    df = pd.concat([df_red, df_white])\n",
    "    \n",
    "    print(df.size)\n",
    "    le = LabelEncoder()\n",
    "    le.fit(df.iloc[:, -1])\n",
    "    y = le.transform(df.iloc[:, -1]) # label\n",
    "    X = df.drop([df.columns[0], 'color'], axis=1)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def titanic():\n",
    "    train = pd.read_csv('../cso_cnn/datasets/titanic_train.csv')\n",
    "    test = pd.read_csv('../cso_cnn/datasets/titanic_test.csv')\n",
    "    \n",
    "    full_data = [train, test]\n",
    "    \n",
    "    PassengerId = test['PassengerId']\n",
    "    # Some features of my own that I have added in\n",
    "    # Gives the length of the name\n",
    "    train['Name_length'] = train['Name'].apply(len)\n",
    "    test['Name_length'] = test['Name'].apply(len)\n",
    "    # Feature that tells whether a passenger had a cabin on the Titanic\n",
    "    train['Has_Cabin'] = train[\"Cabin\"].apply(lambda x: 0 if type(x) == float else 1)\n",
    "    test['Has_Cabin'] = test[\"Cabin\"].apply(lambda x: 0 if type(x) == float else 1)\n",
    "\n",
    "    # Feature engineering steps taken from Sina\n",
    "    # Create new feature FamilySize as a combination of SibSp and Parch\n",
    "    for dataset in full_data:\n",
    "        dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1\n",
    "    # Create new feature IsAlone from FamilySize\n",
    "    for dataset in full_data:\n",
    "        dataset['IsAlone'] = 0\n",
    "        dataset.loc[dataset['FamilySize'] == 1, 'IsAlone'] = 1\n",
    "    # Remove all NULLS in the Embarked column\n",
    "    for dataset in full_data:\n",
    "        dataset['Embarked'] = dataset['Embarked'].fillna('S')\n",
    "    # Remove all NULLS in the Fare column and create a new feature CategoricalFare\n",
    "    for dataset in full_data:\n",
    "        dataset['Fare'] = dataset['Fare'].fillna(train['Fare'].median())\n",
    "    train['CategoricalFare'] = pd.qcut(train['Fare'], 4)\n",
    "    # Create a New feature CategoricalAge\n",
    "    for dataset in full_data:\n",
    "        age_avg = dataset['Age'].mean()\n",
    "        age_std = dataset['Age'].std()\n",
    "        age_null_count = dataset['Age'].isnull().sum()\n",
    "        age_null_random_list = np.random.randint(age_avg - age_std, age_avg + age_std, size=age_null_count)\n",
    "        dataset['Age'][np.isnan(dataset['Age'])] = age_null_random_list\n",
    "        dataset['Age'] = dataset['Age'].astype(int)\n",
    "    train['CategoricalAge'] = pd.cut(train['Age'], 5)\n",
    "    # Define function to extract titles from passenger names\n",
    "    def get_title(name):\n",
    "        title_search = re.search(' ([A-Za-z]+)\\.', name)\n",
    "        # If the title exists, extract and return it.\n",
    "        if title_search:\n",
    "            return title_search.group(1)\n",
    "        return \"\"\n",
    "    # Create a new feature Title, containing the titles of passenger names\n",
    "    for dataset in full_data:\n",
    "        dataset['Title'] = dataset['Name'].apply(get_title)\n",
    "    # Group all non-common titles into one single grouping \"Rare\"\n",
    "    for dataset in full_data:\n",
    "        dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
    "\n",
    "        dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n",
    "        dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n",
    "        dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n",
    "\n",
    "    for dataset in full_data:\n",
    "        # Mapping Sex\n",
    "        dataset['Sex'] = dataset['Sex'].map( {'female': 0, 'male': 1} ).astype(int)\n",
    "\n",
    "        # Mapping titles\n",
    "        title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\n",
    "        dataset['Title'] = dataset['Title'].map(title_mapping)\n",
    "        dataset['Title'] = dataset['Title'].fillna(0)\n",
    "\n",
    "        # Mapping Embarked\n",
    "        dataset['Embarked'] = dataset['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)\n",
    "\n",
    "        # Mapping Fare\n",
    "        dataset.loc[ dataset['Fare'] <= 7.91, 'Fare'] \t\t\t\t\t\t        = 0\n",
    "        dataset.loc[(dataset['Fare'] > 7.91) & (dataset['Fare'] <= 14.454), 'Fare'] = 1\n",
    "        dataset.loc[(dataset['Fare'] > 14.454) & (dataset['Fare'] <= 31), 'Fare']   = 2\n",
    "        dataset.loc[ dataset['Fare'] > 31, 'Fare'] \t\t\t\t\t\t\t        = 3\n",
    "        dataset['Fare'] = dataset['Fare'].astype(int)\n",
    "\n",
    "        # Mapping Age\n",
    "        dataset.loc[ dataset['Age'] <= 16, 'Age'] \t\t\t\t\t       = 0\n",
    "        dataset.loc[(dataset['Age'] > 16) & (dataset['Age'] <= 32), 'Age'] = 1\n",
    "        dataset.loc[(dataset['Age'] > 32) & (dataset['Age'] <= 48), 'Age'] = 2\n",
    "        dataset.loc[(dataset['Age'] > 48) & (dataset['Age'] <= 64), 'Age'] = 3\n",
    "        dataset.loc[ dataset['Age'] > 64, 'Age'] = 4 ;\n",
    "    # Feature selection\n",
    "    drop_elements = ['PassengerId', 'Name', 'Ticket', 'Cabin', 'SibSp']\n",
    "    train = train.drop(drop_elements, axis = 1)\n",
    "    train = train.drop(['CategoricalAge', 'CategoricalFare'], axis = 1)\n",
    "    test  = test.drop(drop_elements, axis = 1)\n",
    "    le = LabelEncoder()\n",
    "    le.fit(train.iloc[:, 1])\n",
    "    y = le.transform(train.iloc[:, 1])\n",
    "    X = train.drop([train.columns[0], 'Survived'], axis=1)\n",
    "    print(X.size)\n",
    "    print(y.size)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['setosa' 'versicolor' 'virginica']\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9801\n",
      "891\n",
      "Accuracy with all features: \t(0.9495425786109596,)\n",
      "\n",
      "xx\n",
      "gen\tnevals\tavg     \tmin\tmax    \n",
      "0  \t100   \t0.797534\t0  \t0.95522\n",
      "1  \t71    \t0.882596\t0.589852\t0.95522\n",
      "2  \t47    \t0.92739 \t0.543066\t0.962681\n",
      "3  \t65    \t0.939931\t0.756299\t0.962681\n",
      "4  \t62    \t0.947206\t0.745048\t0.962681\n",
      "5  \t63    \t0.953515\t0.906494\t0.966333\n",
      "6  \t62    \t0.957833\t0.913937\t0.966333\n",
      "7  \t59    \t0.959226\t0.730283\t0.966333\n",
      "8  \t63    \t0.962542\t0.906512\t0.966333\n",
      "9  \t64    \t0.958427\t0.73217 \t0.966333\n",
      "10 \t65    \t0.962887\t0.883783\t0.966333\n",
      "11 \t70    \t0.963693\t0.881914\t0.966333\n",
      "12 \t49    \t0.964737\t0.904573\t0.966333\n",
      "13 \t51    \t0.959666\t0.733884\t0.966333\n",
      "14 \t56    \t0.964667\t0.925066\t0.966333\n",
      "15 \t53    \t0.962566\t0.810964\t0.966333\n",
      "16 \t60    \t0.962326\t0.805356\t0.966333\n",
      "17 \t64    \t0.957905\t0.737762\t0.966333\n",
      "18 \t50    \t0.962754\t0.737762\t0.966333\n",
      "19 \t61    \t0.963485\t0.805356\t0.966333\n",
      "20 \t61    \t0.961741\t0.735892\t0.966333\n",
      " hall of frame : 2000\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'float'>\n",
      "Best Accuracy: \t(0.9663326533352532,)\n",
      "Number of Features in Subset: \t5\n",
      "Individual: \t\t[1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0]\n",
      "Feature Subset\t: ['Pclass', 'Sex', 'Has_Cabin', 'FamilySize', 'IsAlone']\n",
      "\n",
      "\n",
      "creating a new classifier with the result\n",
      "Accuracy with Feature Subset: \t1.0\n",
      "\n",
      "Tuned Decision Tree Parameters: {'criterion': 'entropy', 'max_depth': None, 'max_features': 4, 'min_samples_leaf': 4}\n",
      "Best score is 1.0\n",
      "Test acc : 0.988795518207283\n"
     ]
    }
   ],
   "source": [
    "n_pop = 100\n",
    "n_gen = 20\n",
    "# read dataframe from csv\n",
    "df = pd.read_csv('datasets/iris.csv',)\n",
    "le = LabelEncoder()\n",
    "le.fit(df.iloc[:, -1])\n",
    "y = le.transform(df.iloc[:, -1]) # label\n",
    "print(le.classes_)\n",
    "print(y)\n",
    "X = df.drop([df.columns[0], 'Species'], axis=1)\n",
    "\n",
    "X,y = titanic()\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train,x_test,y_train, y_test = train_test_split(X , y , test_size=0.4 , random_state=0)\n",
    "\n",
    "# get accuracy with all features\n",
    "individual = [1 for i in range(len(x_train.columns))] # true column (feature)\n",
    "print(\"Accuracy with all features: \\t\" +\n",
    "      str(getFitness(individual, x_train, y_train)) + \"\\n\")\n",
    "\n",
    "\n",
    "# apply genetic algorithm\n",
    "hof = geneticAlgorithm(x_train, y_train , n_pop, n_gen)\n",
    "\n",
    "# select the best individual\n",
    "accuracy, individual, header = bestIndividual(hof, x_train, y_train)\n",
    "print('Best Accuracy: \\t' + str(accuracy))\n",
    "print('Number of Features in Subset: \\t' + str(individual.count(1)))\n",
    "print('Individual: \\t\\t' + str(individual))\n",
    "print('Feature Subset\\t: ' + str(header))\n",
    "\n",
    "print('\\n\\ncreating a new classifier with the result')\n",
    "\n",
    "# read dataframe from csv one more time\n",
    "# df = pd.read_csv('datasets/iris.csv', sep=',')\n",
    "\n",
    "# with feature subset\n",
    "x_train = x_train[header]\n",
    "x_test = x_test[header]\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "scores = cross_val_score(clf, x_train, y_train, cv=5)\n",
    "print(\"Accuracy with Feature Subset: \\t\" + str(avg(scores)) + \"\\n\")\n",
    "\n",
    "# Import necessary modules\n",
    "from scipy.stats import randint\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Setup the parameters and distributions to sample from: param_dist\n",
    "param_dist = {\"max_depth\": [3, None],\n",
    "              \"max_features\": randint(1, len(header)),\n",
    "              \"min_samples_leaf\": randint(1, len(header)),\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}\n",
    "\n",
    "# Instantiate the RandomizedSearchCV object: tree_cv\n",
    "tree_cv = RandomizedSearchCV(DecisionTreeClassifier(), param_dist, cv=5)\n",
    "tree_cv2 = RandomizedSearchCV(DecisionTreeClassifier(), param_dist, cv=5)\n",
    "# Fit it to the data\n",
    "tree_cv.fit(x_train, y_train)\n",
    "predicted = tree_cv.predict(x_test)\n",
    "# Print the tuned parameters and score\n",
    "\n",
    "print(\"Tuned Decision Tree Parameters: {}\".format(tree_cv.best_params_))\n",
    "print(\"Best score is {}\".format(tree_cv.best_score_))\n",
    "\n",
    "\n",
    "# model = LogisticRegression()\n",
    "# model.fit(x_train, y_train)\n",
    "# predicted = model.predict(x_test)\n",
    "\n",
    "\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "scores = f1_score(predicted, y_test, average='micro')\n",
    "print(\"Test acc : {}\".format(scores))\n",
    "\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "score = cross_val_score(tree_cv2, x_train, y_train, cv=5)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
